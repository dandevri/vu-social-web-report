\section{Discussion}
In the aftermath of the Cambridge Analytica scandal \cite{cambridge}), it has become increasingly more difficult to scrape or mine SNSs.
The events surrounding the 2020 election have, albeit rightfully so, resulted in more robust privacy protection legislation and technological development in privacy protection.
Thus, user-generated content and metadata are difficult to gather, due to verification systems, rate limiting and in general, simply guarded off content. 
Most API access is heavily restricted and only available after extensive background checks.
Most data API endpoints are being rate limited, or blocked.
Eventhough these are considered good practices for public endpoints, the extent to which SNS data endpoints experience them make gathering large datasets difficult or time consuming.
Compounded onto historical precedent, the fear of AI scraping is becoming increasingly tense.
For example, twitter rate limited their API \cite{Twitter} recently, and developers now need to pay for Reddit API usage \cite{reddit}).
Moreover, it may not always be for privacy protection, as the aforementioned cases also have a high profit incentive for the companies.

This causes severe restrictions in accessing, processing and using social media data in social web related research. However, on the other hand, platforms such as Mastodon, used in this research project, allow for a relatively unfettered access to users' toots. This leads to privacy breaches according to well-known information privacy regulation laws like the EU's GDPR (General Data Protection Regulation) \cite{gdpr}. According to this regulation, transparency, consent as well as data protection by design and by default are some of the key tenets that need to be ensured in order to safeguard users' information privacy. This regulation applies to this project as the instances gathered were in a european GDPR regulated territory. 

